{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (4.1.2)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from gensim) (1.7.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from gensim) (1.21.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from gensim) (5.2.1)\n",
            "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 22.0.4 is available.\n",
            "You should consider upgrading via the '/Users/max/.pyenv/versions/3.7.11/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: setuptools in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from tensorflow) (47.1.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from tensorflow) (0.24.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from tensorflow) (1.44.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from tensorflow) (13.0.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from tensorflow) (1.21.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from tensorflow) (3.6.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from tensorflow) (3.20.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.1.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.6.2)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.8.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.0.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 22.0.4 is available.\n",
            "You should consider upgrading via the '/Users/max/.pyenv/versions/3.7.11/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-hub in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from tensorflow-hub) (1.21.3)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from tensorflow-hub) (3.20.0)\n",
            "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 22.0.4 is available.\n",
            "You should consider upgrading via the '/Users/max/.pyenv/versions/3.7.11/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (3.7)\n",
            "Requirement already satisfied: joblib in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from nltk) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from nltk) (4.63.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from nltk) (2022.3.15)\n",
            "Requirement already satisfied: click in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from nltk) (8.1.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from click->nltk) (4.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->click->nltk) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->click->nltk) (3.6.0)\n",
            "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 22.0.4 is available.\n",
            "You should consider upgrading via the '/Users/max/.pyenv/versions/3.7.11/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.0.tar.gz (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 3.0 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting transformers<5.0.0,>=4.6.0\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 9.1 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from sentence-transformers) (4.63.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from sentence-transformers) (1.10.0)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.12.0-cp37-cp37m-macosx_10_9_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 36.6 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: numpy in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from sentence-transformers) (1.21.3)\n",
            "Requirement already satisfied: scikit-learn in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied: scipy in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from sentence-transformers) (1.7.1)\n",
            "Requirement already satisfied: nltk in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from sentence-transformers) (3.7)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-macosx_10_6_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 32.6 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 8.7 MB/s  eta 0:00:01\n",
            "\u001b[?25hCollecting packaging>=20.0\n",
            "  Using cached packaging-21.3-py3-none-any.whl (40 kB)\n",
            "Collecting filelock\n",
            "  Downloading filelock-3.6.0-py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.8.1)\n",
            "Requirement already satisfied: requests in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.27.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.3.15)\n",
            "Collecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-macosx_10_11_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 24.6 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Using cached PyYAML-6.0-cp37-cp37m-macosx_10_9_x86_64.whl (189 kB)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 43.9 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from torch>=1.6.0->sentence-transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from torchvision->sentence-transformers) (8.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from scikit-learn->sentence-transformers) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from scikit-learn->sentence-transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from nltk->sentence-transformers) (8.1.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.26.9)\n",
            "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: six in /Users/max/.pyenv/versions/3.7.11/lib/python3.7/site-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.16.0)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.0-py3-none-any.whl size=120747 sha256=090e0ee5ed789b85b8841e4d3ecbb142cebb77ea53a79d46c7b436a3637fc222\n",
            "  Stored in directory: /Users/max/Library/Caches/pip/wheels/83/c0/df/b6873ab7aac3f2465aa9144b6b4c41c4391cfecc027c8b07e7\n",
            "Successfully built sentence-transformers\n",
            "\u001b[31mERROR: torchvision 0.12.0 has requirement torch==1.11.0, but you'll have torch 1.10.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: packaging, filelock, tokenizers, pyyaml, huggingface-hub, sacremoses, transformers, torchvision, sentencepiece, sentence-transformers\n",
            "Successfully installed filelock-3.6.0 huggingface-hub-0.4.0 packaging-21.3 pyyaml-6.0 sacremoses-0.0.49 sentence-transformers-2.2.0 sentencepiece-0.1.96 tokenizers-0.11.6 torchvision-0.12.0 transformers-4.17.0\n",
            "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 22.0.4 is available.\n",
            "You should consider upgrading via the '/Users/max/.pyenv/versions/3.7.11/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZqVO-tI_aRu",
        "outputId": "4700d44a-9b12-4479-9f66-97f900c22482"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/max/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "import tensorflow_hub as hub\n",
        "from nltk.tokenize import word_tokenize\n",
        "from scipy import spatial\n",
        "import nltk\n",
        "from sentence_transformers import SentenceTransformer\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZb5GgZ3CNY5"
      },
      "source": [
        "here we generate the dataframe, which keyword named as title and GT recommendation named as content.\n",
        "\n",
        "We are using here just the NYT articles, as buy using articles from just one publisher we hope to get a better more consistant matching and less confusion, which is important, when building the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ud_VKIQAAJuj",
        "outputId": "4c57ecd2-b6d0-4c6d-e8d7-31df4961d81c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>House Republicans Fret About Winning Their Hea...</td>\n",
              "      <td>WASHINGTON  —   Congressional Republicans have...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Rift Between Officers and Residents as Killing...</td>\n",
              "      <td>After the bullet shells get counted, the blood...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial ...</td>\n",
              "      <td>When Walt Disney’s “Bambi” opened in 1942, cri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Among Deaths in 2016, a Heavy Toll in Pop Musi...</td>\n",
              "      <td>Death may be the great equalizer, but it isn’t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Kim Jong-un Says North Korea Is Preparing to T...</td>\n",
              "      <td>SEOUL, South Korea  —   North Korea’s leader, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7798</th>\n",
              "      <td>U.N. Relief Official Calls Crisis in Aleppo th...</td>\n",
              "      <td>The top aid official at the United Nations gav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7799</th>\n",
              "      <td>Federal Judge Curbs Enforcement of North Carol...</td>\n",
              "      <td>A federal judge on Friday curbed the enforceme...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7800</th>\n",
              "      <td>Mexicans Accuse President of ‘Historic Error’ ...</td>\n",
              "      <td>MEXICO CITY  —   If President Enrique Peña Nie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7801</th>\n",
              "      <td>U.S. Presses for Truce in Syria, With Its Larg...</td>\n",
              "      <td>HANGZHOU, China  —   The image of a    Syrian ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7802</th>\n",
              "      <td>Airbnb Adopts Rules to Fight Discrimination by...</td>\n",
              "      <td>SAN FRANCISCO  —   For much of this year, Airb...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7803 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  title  \\\n",
              "0     House Republicans Fret About Winning Their Hea...   \n",
              "1     Rift Between Officers and Residents as Killing...   \n",
              "2     Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial ...   \n",
              "3     Among Deaths in 2016, a Heavy Toll in Pop Musi...   \n",
              "4     Kim Jong-un Says North Korea Is Preparing to T...   \n",
              "...                                                 ...   \n",
              "7798  U.N. Relief Official Calls Crisis in Aleppo th...   \n",
              "7799  Federal Judge Curbs Enforcement of North Carol...   \n",
              "7800  Mexicans Accuse President of ‘Historic Error’ ...   \n",
              "7801  U.S. Presses for Truce in Syria, With Its Larg...   \n",
              "7802  Airbnb Adopts Rules to Fight Discrimination by...   \n",
              "\n",
              "                                                content  \n",
              "0     WASHINGTON  —   Congressional Republicans have...  \n",
              "1     After the bullet shells get counted, the blood...  \n",
              "2     When Walt Disney’s “Bambi” opened in 1942, cri...  \n",
              "3     Death may be the great equalizer, but it isn’t...  \n",
              "4     SEOUL, South Korea  —   North Korea’s leader, ...  \n",
              "...                                                 ...  \n",
              "7798  The top aid official at the United Nations gav...  \n",
              "7799  A federal judge on Friday curbed the enforceme...  \n",
              "7800  MEXICO CITY  —   If President Enrique Peña Nie...  \n",
              "7801  HANGZHOU, China  —   The image of a    Syrian ...  \n",
              "7802  SAN FRANCISCO  —   For much of this year, Airb...  \n",
              "\n",
              "[7803 rows x 2 columns]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('../comparison_dataset/articles1.csv')\n",
        "df = df[df['publication'] == 'New York Times']\n",
        "df = df.drop(columns = ['id', 'publication', 'author', 'date', 'year', 'month', 'url', 'Unnamed: 0'])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9krNii0CWUC"
      },
      "source": [
        "now we try to find embedding methods, which in an ideal matching, or we could also just try to minimize distance between the embedded title and content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "D02XfBTKCK7z"
      },
      "outputs": [],
      "source": [
        "def embedding_by_doc_2_vec(df):\n",
        "  data = df['content']\n",
        "  tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(data)]\n",
        "  # df['tagged_data'] = tagged_data\n",
        "  max_epochs = 5\n",
        "  vec_size = 20\n",
        "  alpha = 0.025\n",
        "\n",
        "  model = Doc2Vec(#size = vec_size,\n",
        "    vector_size=vec_size,\n",
        "                  alpha=alpha, \n",
        "                  min_alpha=0.00025,\n",
        "                  min_count=1,\n",
        "                  dm =1)\n",
        "    \n",
        "  model.build_vocab(tagged_data)\n",
        "\n",
        "  for epoch in range(max_epochs):\n",
        "      print('iteration {0}'.format(epoch))\n",
        "      model.train(tagged_data,\n",
        "                  total_examples=model.corpus_count,\n",
        "                  #epochs = model.iter\n",
        "                  epochs=model.epochs)\n",
        "      # decrease the learning rate\n",
        "      model.alpha -= 0.0002\n",
        "      # fix the learning rate, no decay\n",
        "      model.min_alpha = model.alpha\n",
        "  print('here')\n",
        "  print(model.docvecs['1'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "xCqXk2VHFBgG",
        "outputId": "0f80c9eb-d7ed-41c1-e948-04b4490c12e0"
      },
      "outputs": [],
      "source": [
        "#model_d2v = embedding_by_doc_2_vec(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "#model_d2v.save(\"doc2vec.model\")\n",
        "model_d2v = Doc2Vec.load(\"doc2vec.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>content</th>\n",
              "      <th>embed_title_d2v</th>\n",
              "      <th>embed_content_d2v</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>House Republicans Fret About Winning Their Hea...</td>\n",
              "      <td>WASHINGTON  —   Congressional Republicans have...</td>\n",
              "      <td>[0.0097255735, 0.0013119221, 0.0031621992, -0....</td>\n",
              "      <td>[-0.4876673, -0.03852097, -0.8450327, 5.006812...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Rift Between Officers and Residents as Killing...</td>\n",
              "      <td>After the bullet shells get counted, the blood...</td>\n",
              "      <td>[-0.038155433, 0.32817695, 0.029026736, -0.019...</td>\n",
              "      <td>[3.0910404, 0.4343017, -0.09805204, 0.16859086...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial ...</td>\n",
              "      <td>When Walt Disney’s “Bambi” opened in 1942, cri...</td>\n",
              "      <td>[-0.06825161, 0.5558198, 0.057838302, -0.01888...</td>\n",
              "      <td>[1.2336452, 2.1413794, 2.6180854, -3.2745428, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Among Deaths in 2016, a Heavy Toll in Pop Musi...</td>\n",
              "      <td>Death may be the great equalizer, but it isn’t...</td>\n",
              "      <td>[-0.06487101, 0.12077401, 0.030435491, 0.12945...</td>\n",
              "      <td>[-1.9785938, 2.9619815, 6.096006, -0.8292187, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Kim Jong-un Says North Korea Is Preparing to T...</td>\n",
              "      <td>SEOUL, South Korea  —   North Korea’s leader, ...</td>\n",
              "      <td>[-0.05594013, 0.07169301, 0.031006414, -0.0133...</td>\n",
              "      <td>[0.68977714, 3.0600314, 3.0057077, 2.6856246, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7798</th>\n",
              "      <td>U.N. Relief Official Calls Crisis in Aleppo th...</td>\n",
              "      <td>The top aid official at the United Nations gav...</td>\n",
              "      <td>[-0.07153671, 0.20067534, 0.0070963474, 0.0630...</td>\n",
              "      <td>[1.3940898, 1.8590791, 0.84730095, 1.3343887, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7799</th>\n",
              "      <td>Federal Judge Curbs Enforcement of North Carol...</td>\n",
              "      <td>A federal judge on Friday curbed the enforceme...</td>\n",
              "      <td>[0.004603547, 0.019374434, -0.011322883, -0.01...</td>\n",
              "      <td>[0.24817775, -2.4326952, -2.1218348, 2.196453,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7800</th>\n",
              "      <td>Mexicans Accuse President of ‘Historic Error’ ...</td>\n",
              "      <td>MEXICO CITY  —   If President Enrique Peña Nie...</td>\n",
              "      <td>[-0.028931862, 0.0069274977, -0.0069188196, 0....</td>\n",
              "      <td>[0.4804474, 2.163277, 0.16321248, 2.232962, 2....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7801</th>\n",
              "      <td>U.S. Presses for Truce in Syria, With Its Larg...</td>\n",
              "      <td>HANGZHOU, China  —   The image of a    Syrian ...</td>\n",
              "      <td>[-0.022897683, 0.3731831, -0.033410747, 0.0183...</td>\n",
              "      <td>[0.65167874, 2.3952546, 1.9429837, 3.6491663, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7802</th>\n",
              "      <td>Airbnb Adopts Rules to Fight Discrimination by...</td>\n",
              "      <td>SAN FRANCISCO  —   For much of this year, Airb...</td>\n",
              "      <td>[-0.1070118, 0.20264082, 0.014087747, 0.009643...</td>\n",
              "      <td>[1.5474335, 2.16579, -4.9001217, 1.928647, 1.3...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7803 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  title  \\\n",
              "0     House Republicans Fret About Winning Their Hea...   \n",
              "1     Rift Between Officers and Residents as Killing...   \n",
              "2     Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial ...   \n",
              "3     Among Deaths in 2016, a Heavy Toll in Pop Musi...   \n",
              "4     Kim Jong-un Says North Korea Is Preparing to T...   \n",
              "...                                                 ...   \n",
              "7798  U.N. Relief Official Calls Crisis in Aleppo th...   \n",
              "7799  Federal Judge Curbs Enforcement of North Carol...   \n",
              "7800  Mexicans Accuse President of ‘Historic Error’ ...   \n",
              "7801  U.S. Presses for Truce in Syria, With Its Larg...   \n",
              "7802  Airbnb Adopts Rules to Fight Discrimination by...   \n",
              "\n",
              "                                                content  \\\n",
              "0     WASHINGTON  —   Congressional Republicans have...   \n",
              "1     After the bullet shells get counted, the blood...   \n",
              "2     When Walt Disney’s “Bambi” opened in 1942, cri...   \n",
              "3     Death may be the great equalizer, but it isn’t...   \n",
              "4     SEOUL, South Korea  —   North Korea’s leader, ...   \n",
              "...                                                 ...   \n",
              "7798  The top aid official at the United Nations gav...   \n",
              "7799  A federal judge on Friday curbed the enforceme...   \n",
              "7800  MEXICO CITY  —   If President Enrique Peña Nie...   \n",
              "7801  HANGZHOU, China  —   The image of a    Syrian ...   \n",
              "7802  SAN FRANCISCO  —   For much of this year, Airb...   \n",
              "\n",
              "                                        embed_title_d2v  \\\n",
              "0     [0.0097255735, 0.0013119221, 0.0031621992, -0....   \n",
              "1     [-0.038155433, 0.32817695, 0.029026736, -0.019...   \n",
              "2     [-0.06825161, 0.5558198, 0.057838302, -0.01888...   \n",
              "3     [-0.06487101, 0.12077401, 0.030435491, 0.12945...   \n",
              "4     [-0.05594013, 0.07169301, 0.031006414, -0.0133...   \n",
              "...                                                 ...   \n",
              "7798  [-0.07153671, 0.20067534, 0.0070963474, 0.0630...   \n",
              "7799  [0.004603547, 0.019374434, -0.011322883, -0.01...   \n",
              "7800  [-0.028931862, 0.0069274977, -0.0069188196, 0....   \n",
              "7801  [-0.022897683, 0.3731831, -0.033410747, 0.0183...   \n",
              "7802  [-0.1070118, 0.20264082, 0.014087747, 0.009643...   \n",
              "\n",
              "                                      embed_content_d2v  \n",
              "0     [-0.4876673, -0.03852097, -0.8450327, 5.006812...  \n",
              "1     [3.0910404, 0.4343017, -0.09805204, 0.16859086...  \n",
              "2     [1.2336452, 2.1413794, 2.6180854, -3.2745428, ...  \n",
              "3     [-1.9785938, 2.9619815, 6.096006, -0.8292187, ...  \n",
              "4     [0.68977714, 3.0600314, 3.0057077, 2.6856246, ...  \n",
              "...                                                 ...  \n",
              "7798  [1.3940898, 1.8590791, 0.84730095, 1.3343887, ...  \n",
              "7799  [0.24817775, -2.4326952, -2.1218348, 2.196453,...  \n",
              "7800  [0.4804474, 2.163277, 0.16321248, 2.232962, 2....  \n",
              "7801  [0.65167874, 2.3952546, 1.9429837, 3.6491663, ...  \n",
              "7802  [1.5474335, 2.16579, -4.9001217, 1.928647, 1.3...  \n",
              "\n",
              "[7803 rows x 4 columns]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def embedd_d2v(model, doc):\n",
        "    return model.infer_vector(doc.split())\n",
        "\n",
        "df['embed_title_d2v'] = df['title'].apply(lambda x: embedd_d2v(model_d2v, x))\n",
        "df['embed_content_d2v'] = df['content'].apply(lambda x: embedd_d2v(model_d2v, x))\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cosine_similarity(df):\n",
        "    return 1 - spatial.distance.cosine(df[0], df[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.37332964408136426"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['d2v_similarity'] = df[['embed_title_d2v', 'embed_content_d2v']].apply(cosine_similarity, axis = 1)\n",
        "df['d2v_similarity'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.4937262279795504"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embed_USE = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "\n",
        "def embed_with_USE(embedder , x):\n",
        "    return embedder(x.split('.')).numpy().mean(axis = 0)\n",
        "\n",
        "df['embed_title_USE'] = df['title'].apply(lambda x: embed_with_USE(embed_USE, x))\n",
        "df['embed_content_USE'] = df['content'].apply(lambda x: embed_with_USE(embed_USE, x))\n",
        "df['USE_similarity'] = df[['embed_title_USE', 'embed_content_USE']].apply(cosine_similarity, axis = 1)\n",
        "df['USE_similarity'].mean()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5456832346447217"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_BERT = SentenceTransformer(r\"sentence-transformers/paraphrase-MiniLM-L6-v2\")\n",
        "\n",
        "def embed_with_USE(model , x):\n",
        "    return model.encode(x)\n",
        "\n",
        "df['embed_title_BERT'] = df['title'].apply(lambda x: embed_with_USE(model_BERT, x))\n",
        "df['embed_content_BERT'] = df['content'].apply(lambda x: embed_with_USE(model_BERT, x))\n",
        "df['BERT_similarity'] = df[['embed_title_BERT', 'embed_content_BERT']].apply(cosine_similarity, axis = 1)\n",
        "df['BERT_similarity'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "variable_scope module_1/ was unused but the corresponding name_scope was already taken.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/ff/v8q71qfn4hbdkzbpmf28ymsr0000gn/T/ipykernel_21878/368735906.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0melmo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://tfhub.dev/google/elmo/2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m embeddings = elmo(\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0;34m\"the cat is on the mat\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dogs are in the fog\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"default\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     as_dict=True)[\"elmo\"]\n",
            "\u001b[0;32m~/.pyenv/versions/3.7.11/lib/python3.7/site-packages/tensorflow_hub/module.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, spec, trainable, name, tags)\u001b[0m\n\u001b[1;32m    163\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No such graph variant: tags=%r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m     \u001b[0mabs_state_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_get_state_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmark_name_scope_used\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs_state_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.pyenv/versions/3.7.11/lib/python3.7/site-packages/tensorflow_hub/module.py\u001b[0m in \u001b[0;36m_try_get_state_scope\u001b[0;34m(name, mark_name_scope_used)\u001b[0m\n\u001b[1;32m    401\u001b[0m       raise RuntimeError(\n\u001b[1;32m    402\u001b[0m           \u001b[0;34m\"variable_scope %s was unused but the corresponding \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m           \"name_scope was already taken.\" % abs_state_scope)\n\u001b[0m\u001b[1;32m    404\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mabs_state_scope\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: variable_scope module_1/ was unused but the corresponding name_scope was already taken."
          ]
        }
      ],
      "source": [
        "elmo2 = hub.Module(\"https://tfhub.dev/google/elmo/2\")\n",
        "embeddings = elmo2(\n",
        "    [\"the cat is on the mat\", \"dogs are in the fog\"],\n",
        "    signature=\"default\",\n",
        "    as_dict=True)[\"elmo\"]\n",
        "embeddings"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
